{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03eb2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "#import chromadb\n",
    "from typing import Annotated, TYPE_CHECKING\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe6ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the asynchronous OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "    base_url=\"https://models.inference.ai.azure.com/\"\n",
    ")\n",
    "\n",
    "# Create the OpenAI Chat Completion Service\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6a04c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.models import FileSearchTool, OpenAIFile, VectorStore\n",
    "from semantic_kernel.agents import AzureAIAgent, AzureAIAgentThread\n",
    "#from blood_pressure_plugin import BloodPressurePlugin  # Tu plugin personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec225ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bp_plugin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 211\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Parte 2: Configuración del Agente\u001b[39;00m\n\u001b[32m    193\u001b[39m AGENT_INSTRUCTIONS = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[33mYou are a helpful AI Agent specialized in generating and analyzing synthetic blood pressure data.\u001b[39m\n\u001b[32m    195\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33mAlways prioritize user inputs. If they mention a number of samples or a filename, use those values. Otherwise, use intelligent defaults.\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    209\u001b[39m agent = ChatCompletionAgent(\n\u001b[32m    210\u001b[39m     service=chat_completion_service,\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     plugins=[ \u001b[43mbp_plugin\u001b[49m\n\u001b[32m    212\u001b[39m     ],\n\u001b[32m    213\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mBPAgent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    214\u001b[39m     instructions=AGENT_INSTRUCTIONS,\n\u001b[32m    215\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m### Carga tu base de datos real si quieres usarla para muestreo\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[38;5;66;03m##bp_plugin = BloodPressurePlugin(random_state=123)  # Usa tu dataset si quieres\u001b[39;00m\n\u001b[32m    220\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m \n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# Parte 3: Flujo Principal\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n",
      "\u001b[31mNameError\u001b[39m: name 'bp_plugin' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Annotated, Dict, Any, Optional\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class BloodPressurePlugin:\n",
    "    \"\"\"Genera registros sintéticos de presión arterial basados en un DataFrame existente o de cero.\"\"\"\n",
    "    def __init__(self, data: Optional[pd.DataFrame] = None, random_state: int = 42):\n",
    "        # Si no se provee data, inicializa vacío\n",
    "        self.df = data.copy() if data is not None else pd.DataFrame()\n",
    "        self._rng = np.random.default_rng(random_state)\n",
    "\n",
    "    @kernel_function(description=\"Provee n registros sintéticos de presión arterial.\")\n",
    "    def generate_synthetic_data(\n",
    "        self,\n",
    "        n_samples: Annotated[int, \"Número de muestras a generar\"],\n",
    "        output_file: Annotated[Optional[str], \"Ruta CSV para guardar, opcional\"] = None\n",
    "    ) -> Annotated[pd.DataFrame, \"DataFrame con datos sintéticos de presión arterial\"]:\n",
    "        \"\"\"\n",
    "        Genera un DataFrame con n_samples registros sintéticos.\n",
    "        Si output_file es provisto, guarda el CSV.\n",
    "        \"\"\"\n",
    "        # Parámetros base\n",
    "        base_sys, base_dia = 120, 80\n",
    "        rows = []\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            # Muestreo de fila base si existe df\n",
    "            if not self.df.empty:\n",
    "                row0 = self.df.sample(n=1, random_state=self._rng.bit_generator).iloc[0].to_dict()\n",
    "            else:\n",
    "                row0 = {}\n",
    "\n",
    "            # Generación de variables demográficas y de salud\n",
    "            age = max(18, min(90, self._rng.normal(45, 15)))\n",
    "            gender = self._rng.choice(['Male', 'Female'])\n",
    "            height_cm = float(\n",
    "                self._rng.normal(175, 8) if gender=='Male' else self._rng.normal(162,7)\n",
    "            )\n",
    "            weight_kg = float(\n",
    "                self._rng.normal(80, 15) if gender=='Male' else self._rng.normal(65,12)\n",
    "            )\n",
    "            bmi = weight_kg / ((height_cm/100) ** 2)\n",
    "            smoking = self._rng.choice(['Never','Former','Current'], p=[0.6,0.2,0.2])\n",
    "            smoking_num = {'Never':0,'Former':1,'Current':2}[smoking]\n",
    "            exercise = float(self._rng.exponential(3))\n",
    "            stress = int(self._rng.integers(1,11))\n",
    "            heart_rate = float(self._rng.normal(75,10))\n",
    "            cholesterol = float(self._rng.normal(200,40))\n",
    "            glucose = float(self._rng.normal(90,15))\n",
    "            diabetes = bool(self._rng.choice([0,1], p=[0.9,0.1]))\n",
    "            fh_htn = bool(self._rng.choice([0,1], p=[0.7,0.3]))\n",
    "            prev_cv = bool(self._rng.choice([0,1], p=[0.85,0.15]))\n",
    "            on_med = bool(self._rng.choice([0,1], p=[0.8,0.2]))\n",
    "\n",
    "            # Cálculo de efectos\n",
    "            age_eff_s = 0.4 * (age-30)\n",
    "            age_eff_d = 0.25 * (age-30)\n",
    "            bmi_eff_s = 1.5 * (bmi-22.5)\n",
    "            bmi_eff_d = 1.0 * (bmi-22.5)\n",
    "            life_eff_s = 3*smoking_num - 0.5*exercise + 1.0*stress\n",
    "            life_eff_d = 2*smoking_num - 0.3*exercise + 0.7*stress\n",
    "            health_eff_s = (\n",
    "                0.2*(heart_rate-75) + 0.05*(cholesterol-200) + 0.03*(glucose-90)\n",
    "                + 5*diabetes + 4*fh_htn + 7*prev_cv\n",
    "            )\n",
    "            health_eff_d = (\n",
    "                0.1*(heart_rate-75) + 0.03*(cholesterol-200) + 0.02*(glucose-90)\n",
    "                + 3*diabetes + 2*fh_htn + 4*prev_cv\n",
    "            )\n",
    "            med_eff_s = -8 * on_med\n",
    "            med_eff_d = -5 * on_med\n",
    "            gender_eff_s = 2 if gender=='Male' else 0\n",
    "            gender_eff_d = 1 if gender=='Male' else 0\n",
    "\n",
    "            # Lecturas brutas\n",
    "            systolic_bp = (\n",
    "                base_sys + age_eff_s + bmi_eff_s + life_eff_s\n",
    "                + health_eff_s + med_eff_s + gender_eff_s\n",
    "                + self._rng.normal(0,8)\n",
    "            )\n",
    "            diastolic_bp = (\n",
    "                base_dia + age_eff_d + bmi_eff_d + life_eff_d\n",
    "                + health_eff_d + med_eff_d + gender_eff_d\n",
    "                + self._rng.normal(0,5)\n",
    "            )\n",
    "\n",
    "            # Convertir a enteros\n",
    "            systolic_bp = int(np.round(systolic_bp).clip(90,200))\n",
    "            diastolic_bp = int(np.round(diastolic_bp).clip(50,120))\n",
    "\n",
    "            # Añadir fila\n",
    "            rows.append({\n",
    "                'age': round(age,1),\n",
    "                'gender': gender,\n",
    "                'height_cm': round(height_cm,1),\n",
    "                'weight_kg': round(weight_kg,1),\n",
    "                'bmi': round(bmi,2),\n",
    "                'smoking_status': smoking,\n",
    "                'exercise_hours_per_week': round(exercise,1),\n",
    "                'stress_level': stress,\n",
    "                'heart_rate': round(heart_rate,1),\n",
    "                'cholesterol': round(cholesterol,1),\n",
    "                'glucose': round(glucose,1),\n",
    "                'diabetes': diabetes,\n",
    "                'family_history_hypertension': fh_htn,\n",
    "                'previous_cardiovascular_condition': prev_cv,\n",
    "                'on_medication': on_med,\n",
    "                'systolic_bp': systolic_bp,\n",
    "                'diastolic_bp': diastolic_bp\n",
    "            })\n",
    "\n",
    "        # Construir DataFrame\n",
    "        data = pd.DataFrame(rows)\n",
    "\n",
    "        # Guardar si se especifica output_file\n",
    "        if output_file:\n",
    "            os.makedirs(os.path.dirname(os.path.abspath(output_file)), exist_ok=True)\n",
    "            data.to_csv(output_file, index=False)\n",
    "\n",
    "        return data\n",
    "\n",
    "    @kernel_function(description=\"Entrena un modelo para predecir presión arterial.\")\n",
    "    def train_model(\n",
    "        self,\n",
    "        input_file: Annotated[str, \"Ruta CSV de entrenamiento\"],\n",
    "        model_type: Annotated[str, \"Tipo: linear, xgboost, neuralnet\"],\n",
    "        target: Annotated[str, \"Variable objetivo: systolic_bp o diastolic_bp\"],\n",
    "        output_model: Annotated[str, \"Ruta para guardar modelo\"]\n",
    "    ) -> Annotated[str, \"Ruta del modelo guardado\"]:\n",
    "        df = pd.read_csv(input_file)\n",
    "        df = pd.get_dummies(df, columns=[\"gender\", \"smoking_status\"], drop_first=True)\n",
    "\n",
    "        X = df.drop(columns=[\"systolic_bp\", \"diastolic_bp\"])\n",
    "        y = df[target]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        joblib.dump(scaler, output_model + \".scaler\")\n",
    "\n",
    "        if model_type == \"linear\":\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_scaled, y)\n",
    "            joblib.dump(model, output_model)\n",
    "        elif model_type == \"neuralnet\":\n",
    "            model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Input(shape=(X_scaled.shape[1],)),\n",
    "                tf.keras.layers.Dense(64, activation='relu'),\n",
    "                tf.keras.layers.Dense(32, activation='relu'),\n",
    "                tf.keras.layers.Dense(1)\n",
    "            ])\n",
    "            model.compile(optimizer='adam', loss='mse')\n",
    "            model.fit(X_scaled, y, epochs=50, batch_size=32, verbose=0)\n",
    "            model.save(output_model)\n",
    "        else:\n",
    "            return \"Modelo no soportado. Usa 'linear' o 'neuralnet'.\"\n",
    "\n",
    "        return output_model\n",
    "\n",
    "    @kernel_function(description=\"Predice presión arterial a partir de datos nuevos.\")\n",
    "    def predict_bp(\n",
    "        self,\n",
    "        model_file: Annotated[str, \"Ruta al modelo\"],\n",
    "        scaler_file: Annotated[str, \"Ruta al scaler\"],\n",
    "        input_data_file: Annotated[str, \"Ruta al CSV con datos nuevos\"]\n",
    "    ) -> Annotated[str, \"Predicciones de presión arterial\"]:\n",
    "        df = pd.read_csv(input_data_file)\n",
    "        df_proc = pd.get_dummies(df, columns=[\"gender\", \"smoking_status\"], drop_first=True)\n",
    "        X = df_proc\n",
    "\n",
    "        scaler = joblib.load(scaler_file)\n",
    "        X_scaled = scaler.transform(X)\n",
    "\n",
    "        if model_file.endswith(\".h5\"):\n",
    "            model = tf.keras.models.load_model(model_file)\n",
    "            preds = model.predict(X_scaled).flatten()\n",
    "        else:\n",
    "            model = joblib.load(model_file)\n",
    "            preds = model.predict(X_scaled)\n",
    "\n",
    "        df['predicted_bp'] = np.round(preds, 1)\n",
    "        out_path = input_data_file.replace(\".csv\", \"_predicted.csv\")\n",
    "        df.to_csv(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "# Parte 2: Configuración del Agente\n",
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are a helpful AI Agent specialized in generating and analyzing synthetic blood pressure data.\n",
    "\n",
    "Important: When users specify a number of records or a file to save the data, always follow their instructions. Only suggest defaults when the user hasn't specified their preferences.\n",
    "\n",
    "When the conversation begins, introduce yourself with this message:\n",
    "\"Hello! I'm your BloodPressure Assistant. I can help generate synthetic blood pressure data and analyze it to simulate health scenarios. Here are some things you can ask me:\n",
    "1. Generate a specific number of synthetic records (e.g., 100 records)\n",
    "2. Save the generated data to a CSV file\n",
    "3. Get a quick preview of the data\n",
    "4. Help simulate different health conditions for experimentation\n",
    "\n",
    "What would you like me to do for you today?\"\n",
    "\n",
    "Always prioritize user inputs. If they mention a number of samples or a filename, use those values. Otherwise, use intelligent defaults.\n",
    "\"\"\"\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    plugins=[ bp_plugin\n",
    "    ],\n",
    "    name=\"BPAgent\",\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "\n",
    "### Carga tu base de datos real si quieres usarla para muestreo\n",
    "##bp_plugin = BloodPressurePlugin(random_state=123)  # Usa tu dataset si quieres\n",
    "\n",
    "#agent = ChatCompletionAgent(\n",
    "   # service=chat_completion_service,\n",
    "   # plugins=[bp_plugin],\n",
    "   # name=\"BPAgent\",\n",
    "   # instructions=AGENT_INSTRUCTIONS,  # usa tus instrucciones personalizadas\n",
    "#)\n",
    "\n",
    "\n",
    "# Parte 3: Flujo Principal\n",
    "async def main():\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "    user_inputs = [\n",
    "        \"Genera 100 registros sintéticos y guárdalos en data.csv\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(response, end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156120c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b65a161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05e67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735db7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e042b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chromadb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Annotated, TYPE_CHECKING\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'chromadb'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import chromadb\n",
    "from typing import Annotated, TYPE_CHECKING\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from chromadb.api.models.Collection import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae45857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the asynchronous OpenAI client\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"],\n",
    "    base_url=\"https://models.inference.ai.azure.com/\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create the OpenAI Chat Completion Service\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a01e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 170\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\asyncio\\runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Annotated, Dict, Any, Optional\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class BloodPressurePlugin:\n",
    "    \"\"\"Genera registros sintéticos de presión arterial basados en un DataFrame existente o de cero.\"\"\"\n",
    "    def __init__(self, data: Optional[pd.DataFrame] = None, random_state: int = 42):\n",
    "        # Si no se provee data, inicializa vacío\n",
    "        self.df = data.copy() if data is not None else pd.DataFrame()\n",
    "        self._rng = np.random.default_rng(random_state)\n",
    "\n",
    "    @kernel_function(description=\"Provee n registros sintéticos de presión arterial.\")\n",
    "    def generate_synthetic_data(\n",
    "        self,\n",
    "        n_samples: Annotated[int, \"Número de muestras a generar\"],\n",
    "        output_file: Annotated[Optional[str], \"Ruta CSV para guardar, opcional\"] = None\n",
    "    ) -> Annotated[pd.DataFrame, \"DataFrame con datos sintéticos de presión arterial\"]:\n",
    "        \"\"\"\n",
    "        Genera un DataFrame con n_samples registros sintéticos.\n",
    "        Si output_file es provisto, guarda el CSV.\n",
    "        \"\"\"\n",
    "        # Parámetros base\n",
    "        base_sys, base_dia = 120, 80\n",
    "        rows = []\n",
    "\n",
    "        for _ in range(n_samples):\n",
    "            # Muestreo de fila base si existe df\n",
    "            if not self.df.empty:\n",
    "                row0 = self.df.sample(n=1, random_state=self._rng.bit_generator).iloc[0].to_dict()\n",
    "            else:\n",
    "                row0 = {}\n",
    "\n",
    "            # Generación de variables demográficas y de salud\n",
    "            age = max(18, min(90, self._rng.normal(45, 15)))\n",
    "            gender = self._rng.choice(['Male', 'Female'])\n",
    "            height_cm = float(\n",
    "                self._rng.normal(175, 8) if gender=='Male' else self._rng.normal(162,7)\n",
    "            )\n",
    "            weight_kg = float(\n",
    "                self._rng.normal(80, 15) if gender=='Male' else self._rng.normal(65,12)\n",
    "            )\n",
    "            bmi = weight_kg / ((height_cm/100) ** 2)\n",
    "            smoking = self._rng.choice(['Never','Former','Current'], p=[0.6,0.2,0.2])\n",
    "            smoking_num = {'Never':0,'Former':1,'Current':2}[smoking]\n",
    "            exercise = float(self._rng.exponential(3))\n",
    "            stress = int(self._rng.integers(1,11))\n",
    "            heart_rate = float(self._rng.normal(75,10))\n",
    "            cholesterol = float(self._rng.normal(200,40))\n",
    "            glucose = float(self._rng.normal(90,15))\n",
    "            diabetes = bool(self._rng.choice([0,1], p=[0.9,0.1]))\n",
    "            fh_htn = bool(self._rng.choice([0,1], p=[0.7,0.3]))\n",
    "            prev_cv = bool(self._rng.choice([0,1], p=[0.85,0.15]))\n",
    "            on_med = bool(self._rng.choice([0,1], p=[0.8,0.2]))\n",
    "\n",
    "            # Cálculo de efectos\n",
    "            age_eff_s = 0.4 * (age-30)\n",
    "            age_eff_d = 0.25 * (age-30)\n",
    "            bmi_eff_s = 1.5 * (bmi-22.5)\n",
    "            bmi_eff_d = 1.0 * (bmi-22.5)\n",
    "            life_eff_s = 3*smoking_num - 0.5*exercise + 1.0*stress\n",
    "            life_eff_d = 2*smoking_num - 0.3*exercise + 0.7*stress\n",
    "            health_eff_s = (\n",
    "                0.2*(heart_rate-75) + 0.05*(cholesterol-200) + 0.03*(glucose-90)\n",
    "                + 5*diabetes + 4*fh_htn + 7*prev_cv\n",
    "            )\n",
    "            health_eff_d = (\n",
    "                0.1*(heart_rate-75) + 0.03*(cholesterol-200) + 0.02*(glucose-90)\n",
    "                + 3*diabetes + 2*fh_htn + 4*prev_cv\n",
    "            )\n",
    "            med_eff_s = -8 * on_med\n",
    "            med_eff_d = -5 * on_med\n",
    "            gender_eff_s = 2 if gender=='Male' else 0\n",
    "            gender_eff_d = 1 if gender=='Male' else 0\n",
    "\n",
    "            # Lecturas brutas\n",
    "            systolic_bp = (\n",
    "                base_sys + age_eff_s + bmi_eff_s + life_eff_s\n",
    "                + health_eff_s + med_eff_s + gender_eff_s\n",
    "                + self._rng.normal(0,8)\n",
    "            )\n",
    "            diastolic_bp = (\n",
    "                base_dia + age_eff_d + bmi_eff_d + life_eff_d\n",
    "                + health_eff_d + med_eff_d + gender_eff_d\n",
    "                + self._rng.normal(0,5)\n",
    "            )\n",
    "\n",
    "            # Convertir a enteros\n",
    "            systolic_bp = int(np.round(systolic_bp).clip(90,200))\n",
    "            diastolic_bp = int(np.round(diastolic_bp).clip(50,120))\n",
    "\n",
    "            # Añadir fila\n",
    "            rows.append({\n",
    "                'age': round(age,1),\n",
    "                'gender': gender,\n",
    "                'height_cm': round(height_cm,1),\n",
    "                'weight_kg': round(weight_kg,1),\n",
    "                'bmi': round(bmi,2),\n",
    "                'smoking_status': smoking,\n",
    "                'exercise_hours_per_week': round(exercise,1),\n",
    "                'stress_level': stress,\n",
    "                'heart_rate': round(heart_rate,1),\n",
    "                'cholesterol': round(cholesterol,1),\n",
    "                'glucose': round(glucose,1),\n",
    "                'diabetes': diabetes,\n",
    "                'family_history_hypertension': fh_htn,\n",
    "                'previous_cardiovascular_condition': prev_cv,\n",
    "                'on_medication': on_med,\n",
    "                'systolic_bp': systolic_bp,\n",
    "                'diastolic_bp': diastolic_bp\n",
    "            })\n",
    "\n",
    "        # Construir DataFrame\n",
    "        data = pd.DataFrame(rows)\n",
    "\n",
    "        # Guardar si se especifica output_file\n",
    "        if output_file:\n",
    "            os.makedirs(os.path.dirname(os.path.abspath(output_file)), exist_ok=True)\n",
    "            data.to_csv(output_file, index=False)\n",
    "\n",
    "        return data\n",
    "\n",
    "# Parte 2: Configuración del Agente\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "\n",
    "# Carga tu base de datos real si quieres usarla para muestreo\n",
    "# df = pd.read_csv('blood_pressure_dataset.csv')\n",
    "# bp_plugin = BloodPressurePlugin(data=df, random_state=123)\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    plugins=[# bp_plugin\n",
    "    ],\n",
    "    name=\"BPAgent\",\n",
    "    instructions=(\n",
    "        \"Eres un agente que genera registros sintéticos de presión arterial \"\n",
    "        \"basados en una base de datos existente o aleatorios si no se provee.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Parte 3: Flujo Principal\n",
    "async def main():\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "    user_inputs = [\n",
    "        \"Genera 100 registros sintéticos y guárdalos en data.csv\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        print(f\"# User: {user_input}\\n\")\n",
    "        first_chunk = True\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input, thread=thread,\n",
    "        ):\n",
    "            if first_chunk:\n",
    "                print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                first_chunk = False\n",
    "            print(response, end=\"\", flush=True)\n",
    "            thread = response.thread\n",
    "        print()\n",
    "\n",
    "    await thread.delete() if thread else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09410a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAIChatCompletion.__init__() got an unexpected keyword argument 'organization'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Configura el kernel y el servicio de OpenAI\u001b[39;00m\n\u001b[32m     30\u001b[39m kernel = Kernel()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m chat_service = \u001b[43mOpenAIChatCompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mservice_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenai-chat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_ORG_ID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Si es necesario\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m kernel.add_service(chat_service)\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Registra el plugin\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: OpenAIChatCompletion.__init__() got an unexpected keyword argument 'organization'"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Annotated, Dict, Any, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "# Define tu plugin\n",
    "class BloodPressurePlugin:\n",
    "    def _init_(self, random_state: int = 42):\n",
    "        self._rng = np.random.default_rng(random_state)\n",
    "\n",
    "    @kernel_function(description=\"Genera un registro sintético de presión arterial.\")\n",
    "    def generate_synthetic_record(self) -> Annotated[Dict[str, Any], \"Registro de presión arterial sintético\"]:\n",
    "        # Implementa la lógica para generar un registro sintético\n",
    "        age = self._rng.integers(18, 90)\n",
    "        systolic_bp = self._rng.integers(90, 180)\n",
    "        diastolic_bp = self._rng.integers(60, 120)\n",
    "        return {\n",
    "            \"age\": age,\n",
    "            \"systolic_bp\": systolic_bp,\n",
    "            \"diastolic_bp\": diastolic_bp\n",
    "        }\n",
    "\n",
    "# Configura el kernel y el servicio de OpenAI\n",
    "kernel = Kernel()\n",
    "chat_service = OpenAIChatCompletion(\n",
    "    service_id=\"openai-chat\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    organization=os.getenv(\"OPENAI_ORG_ID\")  # Si es necesario\n",
    ")\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "# Registra el plugin\n",
    "bp_plugin = BloodPressurePlugin()\n",
    "kernel.add_plugin(\"BloodPressurePlugin\", bp_plugin)\n",
    "\n",
    "# Configura el agente\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    plugins=[bp_plugin],\n",
    "    name=\"BPAgent\",\n",
    "    instructions=\"Eres un agente que genera registros sintéticos de presión arterial.\"\n",
    ")\n",
    "\n",
    "# Función principal\n",
    "async def main():\n",
    "    thread = ChatHistoryAgentThread()\n",
    "    user_input = \"Genera un registro sintético de presión arterial.\"\n",
    "\n",
    "    async for response in agent.invoke_stream(messages=user_input, thread=thread):\n",
    "        print(response)\n",
    "\n",
    "# Ejecuta la función principal\n",
    "if _name_ == \"_main_\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
